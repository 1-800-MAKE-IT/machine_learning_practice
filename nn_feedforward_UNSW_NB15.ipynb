{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1O9O6LcJqECkog1itkTAD3j6_iw9Q_Fua","authorship_tag":"ABX9TyOzO2TdK4jt/J78bLKc2MGj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giRQC91U89Rr","executionInfo":{"status":"ok","timestamp":1730580109339,"user_tz":0,"elapsed":9707,"user":{"displayName":"Archie Goodman","userId":"05960694724077487952"}},"outputId":"371d4f64-42f8-4551-a654-cb19f6e48eca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Google Drive is already mounted.\n"]}],"source":["#import packages:\n","\n","import os\n","os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n","os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n","\n","from google.colab import drive\n","\n","try:\n","  import google.colab\n","  IN_COLAB = True\n","except:\n","  IN_COLAB = False\n","\n","if IN_COLAB:\n","  # Check if drive is mounted by looking for the mount point in the file system.\n","  # This is a more robust approach than relying on potentially internal variables.\n","  import os\n","  if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","  else:\n","    print(\"Google Drive is already mounted.\")\n","else:\n","  print(\"Not running in Google Colab. Drive mounting skipped.\")\n","\n","\n","import os\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","from tqdm import tqdm\n"]},{"cell_type":"code","source":["\n","#if using colabs - will need to first mount your drive\n","\n","#change these for different users\n","\n","# File paths (update if needed)\n","data_filepath = '/content/drive/MyDrive/Colab_Notebooks/Data/UNSW_NB15_testing-set.parquet'\n","\n","# Load data\n","test_set = pd.read_parquet(test_set_filepath)\n","train_set = pd.read_parquet(training_set_filepath)\n","\n","print(\"Data loaded\")\n","\n"],"metadata":{"id":"XgrmTP8j9Ezy","executionInfo":{"status":"ok","timestamp":1730321429956,"user_tz":0,"elapsed":3653,"user":{"displayName":"Archie Goodman","userId":"05960694724077487952"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b5055e8-f7e8-4c87-b042-dd56b7c108a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loaded\n"]}]},{"cell_type":"code","source":["# Preprocessing function (modified for pandas)\n","def preprocess_data(data_set):\n","  if 'attack_cat' in data_set.columns.tolist():\n","    data_set = data_set.drop('attack_cat', axis=1)\n","\n","  if 'proto' in data_set.columns.tolist():\n","    category_percentages = data_set['proto'].value_counts(normalize=True) * 100\n","\n","    top_6_categories = category_percentages.head(6).index.tolist()\n","\n","    data_set['proto_grouped'] = data_set['proto'].apply(lambda x: x if x in top_6_categories else 'other')\n","\n","    data_set = pd.get_dummies(data_set, columns=['proto_grouped'], prefix='proto_grouped')\n","\n","    data_set = data_set.drop('proto', axis=1)\n","\n","  if 'proto_grouped' in data_set.columns.tolist():\n","      data_set = data_set.drop(['proto_grouped'], axis=1)\n","\n","  categorical_cols = data_set.select_dtypes(include=['category']).columns.tolist()\n","  data_set = pd.get_dummies(data_set, columns=categorical_cols, prefix_sep='_')\n","\n","  binary_cols = data_set.select_dtypes(include=['bool']).columns\n","  data_set[binary_cols] = data_set[binary_cols].astype(int)\n","\n","  print(f\"Data set preprocessed, columns = {data_set.columns.tolist()}\")\n","  return data_set\n","\n","#note to self - train set and test set will have different columns after one-hot encoding, due to different categorical values\n","train_set = preprocess_data(train_set)\n","test_set = preprocess_data(test_set)\n","\n","#add columns called 'state_URN', 'state_no' to test_set dataframe and fill with zeros\n","\n","# Get the difference in columns between the two DataFrames\n","train_set_cols = set(train_set.columns)\n","test_set_cols = set(test_set.columns)\n","\n","missing_in_test = list(train_set_cols - test_set_cols)\n","missing_in_train = list(test_set_cols - train_set_cols)\n","\n","# Add missing columns to test_set and train_set, filled with 0s\n","for col in missing_in_test:\n","    test_set[col] = 0\n","\n","for col in missing_in_train:\n","    train_set[col] = 0\n","\n","#ensure same order\n","test_set = test_set[train_set.columns]\n","\n","# Verify that both DataFrames now have the same columns\n","print(f\"Train set columns: {train_set.columns.tolist()}\")\n","print(f\"Test set columns: {test_set.columns.tolist()}\")\n","\n","assert set(train_set.columns) == set(test_set.columns), \"DataFrames do not have the same columns\"\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k328tarYHctQ","executionInfo":{"status":"ok","timestamp":1730321659943,"user_tz":0,"elapsed":1024,"user":{"displayName":"Archie Goodman","userId":"05960694724077487952"}},"outputId":"30c6ad56-298d-4e35-f268-30ac0b3b61ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data set preprocessed, columns = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'is_sm_ips_ports', 'label', 'proto_grouped_arp', 'proto_grouped_ospf', 'proto_grouped_other', 'proto_grouped_sctp', 'proto_grouped_tcp', 'proto_grouped_udp', 'proto_grouped_unas', 'service_-', 'service_dhcp', 'service_dns', 'service_ftp', 'service_ftp-data', 'service_http', 'service_irc', 'service_pop3', 'service_radius', 'service_smtp', 'service_snmp', 'service_ssh', 'service_ssl', 'state_CON', 'state_ECO', 'state_FIN', 'state_INT', 'state_PAR', 'state_REQ', 'state_RST', 'state_URN', 'state_no', 'state_CLO', 'state_ACC']\n","Data set preprocessed, columns = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'is_sm_ips_ports', 'label', 'proto_grouped_arp', 'proto_grouped_ospf', 'proto_grouped_other', 'proto_grouped_sctp', 'proto_grouped_tcp', 'proto_grouped_udp', 'proto_grouped_unas', 'service_-', 'service_dhcp', 'service_dns', 'service_ftp', 'service_ftp-data', 'service_http', 'service_irc', 'service_pop3', 'service_radius', 'service_smtp', 'service_snmp', 'service_ssh', 'service_ssl', 'state_ACC', 'state_CLO', 'state_CON', 'state_FIN', 'state_INT', 'state_REQ', 'state_RST', 'state_PAR', 'state_no', 'state_URN', 'state_ECO']\n","Train set columns: ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'is_sm_ips_ports', 'label', 'proto_grouped_arp', 'proto_grouped_ospf', 'proto_grouped_other', 'proto_grouped_sctp', 'proto_grouped_tcp', 'proto_grouped_udp', 'proto_grouped_unas', 'service_-', 'service_dhcp', 'service_dns', 'service_ftp', 'service_ftp-data', 'service_http', 'service_irc', 'service_pop3', 'service_radius', 'service_smtp', 'service_snmp', 'service_ssh', 'service_ssl', 'state_CON', 'state_ECO', 'state_FIN', 'state_INT', 'state_PAR', 'state_REQ', 'state_RST', 'state_URN', 'state_no', 'state_CLO', 'state_ACC']\n","Test set columns: ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'is_sm_ips_ports', 'label', 'proto_grouped_arp', 'proto_grouped_ospf', 'proto_grouped_other', 'proto_grouped_sctp', 'proto_grouped_tcp', 'proto_grouped_udp', 'proto_grouped_unas', 'service_-', 'service_dhcp', 'service_dns', 'service_ftp', 'service_ftp-data', 'service_http', 'service_irc', 'service_pop3', 'service_radius', 'service_smtp', 'service_snmp', 'service_ssh', 'service_ssl', 'state_CON', 'state_ECO', 'state_FIN', 'state_INT', 'state_PAR', 'state_REQ', 'state_RST', 'state_URN', 'state_no', 'state_CLO', 'state_ACC']\n"]}]},{"cell_type":"markdown","source":["With a modest class imbalance, these ROC AUC results show that the data is very linearly separable. This is beacuse A. Logistic Regression performs very well, and B. there isn't a large improvement when switching to a Decision Tree model (and an even smaller improvement moving to Random Forest).\n","\n","NOTE - Therefore, there is little justification for using a more complex, less interpetable model on this dataset. I'll choose another: this project is effectively cancelled.\n","\n","Average Validation ROC AUC from nested cross-validation (Logistic Regression): 0.9619402618207303\n","\n","Average Validation ROC AUC from nested cross-validation (Decision Tree): 0.9856269426697901\n","\n","Average Validation ROC AUC from nested cross-validation (Random Forest): 0.9889679397775413\n"],"metadata":{"id":"CiC4Ffi0fcHX"}}]}