{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1cX2lOjHCdxCQCb5mu2Ta83cyJpI45yXA","authorship_tag":"ABX9TyNJzD+YC+EiilSnBn69M02o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","---\n","\n","# Intro"],"metadata":{"id":"zcLoV-sasrXj"}},{"cell_type":"markdown","source":["**Plan**: Import credit card fraud data. Use encoder only transformer network for classifying time series credit card data\n","\n","**Purpose/Intro**: Task is to develop transformer architecture proof of concept for potential application at work, detecting fraud. In a normal data science project it might be considered best practice to begin with more interpretable models first, for research purposes, but this project is solely for the purpose of assessing the viability of a transformer for this task.\n","\n","**Hypothesis**: The attention mechanism of the transformer, when combined with an appropriate positional embedding method, is able to capture both long-term and short-term dependencies in time series credit-card fraud data.\n","\n","**Methodology**: Using cross valdiation techniques on test dataset to calculate appropriate accuracy metrics (adjusting for the significant class imbalance for the dataset), with an aim to assess the viability of transformer networks for fraud classification.\n","\n"],"metadata":{"id":"m8GsCk0-ImyX"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","# Data Sourcing and Processing\n","\n"],"metadata":{"id":"xlTtmyBAt_Wb"}},{"cell_type":"code","source":["\n","#import packages:\n","\n","import os\n","os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n","os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n","\n","from google.colab import drive\n","\n","try:\n","  import google.colab\n","  IN_COLAB = True\n","except:\n","  IN_COLAB = False\n","\n","if IN_COLAB:\n","  # Check if drive is mounted by looking for the mount point in the file system.\n","  # This is a more robust approach than relying on potentially internal variables.\n","  import os\n","  if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","\n","#basics\n","import os\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","#table one\n","!pip install tableone\n","from tableone import TableOne\n","\n","#torch\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","#sklearn\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","\n","from imblearn.over_sampling import RandomOverSampler"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jBqgg1I0MCo","executionInfo":{"status":"ok","timestamp":1733171624989,"user_tz":0,"elapsed":12726,"user":{"displayName":"Archie Goodman","userId":"05960694724077487952"}},"outputId":"9c586b30-0678-4c7e-91c9-9b5dcb040b9a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tableone\n","  Downloading tableone-0.9.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: jinja2>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from tableone) (3.1.4)\n","Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from tableone) (1.26.4)\n","Requirement already satisfied: openpyxl>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from tableone) (3.1.5)\n","Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from tableone) (2.2.2)\n","Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from tableone) (1.13.1)\n","Requirement already satisfied: statsmodels>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tableone) (0.14.4)\n","Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tableone) (0.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.1.4->tableone) (3.0.2)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=3.1.2->tableone) (2.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->tableone) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->tableone) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->tableone) (2024.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.14.1->tableone) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.14.1->tableone) (24.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->tableone) (1.16.0)\n","Downloading tableone-0.9.1-py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tableone\n","Successfully installed tableone-0.9.1\n"]}]},{"cell_type":"code","source":["data_set_filepath = '/content/drive/MyDrive/Colab_Notebooks/Data/creditcard.feather'\n","\n","df = pd.read_feather(data_set_filepath)\n","\n","columns = df.columns.tolist()\n","\n","print(f\"The dataset lenghth is {str(len(df))}\")\n","print(f\"The number of columns is {str(len(columns))}\")\n","print(f\"The column names are {str(columns)}\")\n","df.head(10)\n","\n","table1 = TableOne(df, columns=columns, groupby= 'class', pval=True)\n","print(table1)\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":464},"id":"pHk36Lkm6cUT","executionInfo":{"status":"ok","timestamp":1733171714656,"user_tz":0,"elapsed":577,"user":{"displayName":"Archie Goodman","userId":"05960694724077487952"}},"outputId":"fe78c29b-e642-413f-9c74-2868aef0948d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["The dataset lenghth is 284807\n","The number of columns is 31\n","The column names are ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n"]},{"output_type":"execute_result","data":{"text/plain":["   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n","6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n","7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n","8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n","9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n","4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n","5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n","6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n","7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n","8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n","9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62      0  \n","1  0.125895 -0.008983  0.014724    2.69      0  \n","2 -0.139097 -0.055353 -0.059752  378.66      0  \n","3 -0.221929  0.062723  0.061458  123.50      0  \n","4  0.502292  0.219422  0.215153   69.99      0  \n","5  0.105915  0.253844  0.081080    3.67      0  \n","6 -0.257237  0.034507  0.005168    4.99      0  \n","7 -0.051634 -1.206921 -1.085339   40.80      0  \n","8 -0.384157  0.011747  0.142404   93.20      0  \n","9  0.094199  0.246219  0.083076    3.68      0  \n","\n","[10 rows x 31 columns]"],"text/html":["\n","  <div id=\"df-3c24b1d9-30e4-4a87-9f0f-9c22e6e71daf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>...</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>...</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>149.62</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>...</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>2.69</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>...</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>378.66</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>...</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>123.50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>...</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>69.99</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.0</td>\n","      <td>-0.425966</td>\n","      <td>0.960523</td>\n","      <td>1.141109</td>\n","      <td>-0.168252</td>\n","      <td>0.420987</td>\n","      <td>-0.029728</td>\n","      <td>0.476201</td>\n","      <td>0.260314</td>\n","      <td>-0.568671</td>\n","      <td>...</td>\n","      <td>-0.208254</td>\n","      <td>-0.559825</td>\n","      <td>-0.026398</td>\n","      <td>-0.371427</td>\n","      <td>-0.232794</td>\n","      <td>0.105915</td>\n","      <td>0.253844</td>\n","      <td>0.081080</td>\n","      <td>3.67</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4.0</td>\n","      <td>1.229658</td>\n","      <td>0.141004</td>\n","      <td>0.045371</td>\n","      <td>1.202613</td>\n","      <td>0.191881</td>\n","      <td>0.272708</td>\n","      <td>-0.005159</td>\n","      <td>0.081213</td>\n","      <td>0.464960</td>\n","      <td>...</td>\n","      <td>-0.167716</td>\n","      <td>-0.270710</td>\n","      <td>-0.154104</td>\n","      <td>-0.780055</td>\n","      <td>0.750137</td>\n","      <td>-0.257237</td>\n","      <td>0.034507</td>\n","      <td>0.005168</td>\n","      <td>4.99</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7.0</td>\n","      <td>-0.644269</td>\n","      <td>1.417964</td>\n","      <td>1.074380</td>\n","      <td>-0.492199</td>\n","      <td>0.948934</td>\n","      <td>0.428118</td>\n","      <td>1.120631</td>\n","      <td>-3.807864</td>\n","      <td>0.615375</td>\n","      <td>...</td>\n","      <td>1.943465</td>\n","      <td>-1.015455</td>\n","      <td>0.057504</td>\n","      <td>-0.649709</td>\n","      <td>-0.415267</td>\n","      <td>-0.051634</td>\n","      <td>-1.206921</td>\n","      <td>-1.085339</td>\n","      <td>40.80</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7.0</td>\n","      <td>-0.894286</td>\n","      <td>0.286157</td>\n","      <td>-0.113192</td>\n","      <td>-0.271526</td>\n","      <td>2.669599</td>\n","      <td>3.721818</td>\n","      <td>0.370145</td>\n","      <td>0.851084</td>\n","      <td>-0.392048</td>\n","      <td>...</td>\n","      <td>-0.073425</td>\n","      <td>-0.268092</td>\n","      <td>-0.204233</td>\n","      <td>1.011592</td>\n","      <td>0.373205</td>\n","      <td>-0.384157</td>\n","      <td>0.011747</td>\n","      <td>0.142404</td>\n","      <td>93.20</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9.0</td>\n","      <td>-0.338262</td>\n","      <td>1.119593</td>\n","      <td>1.044367</td>\n","      <td>-0.222187</td>\n","      <td>0.499361</td>\n","      <td>-0.246761</td>\n","      <td>0.651583</td>\n","      <td>0.069539</td>\n","      <td>-0.736727</td>\n","      <td>...</td>\n","      <td>-0.246914</td>\n","      <td>-0.633753</td>\n","      <td>-0.120794</td>\n","      <td>-0.385050</td>\n","      <td>-0.069733</td>\n","      <td>0.094199</td>\n","      <td>0.246219</td>\n","      <td>0.083076</td>\n","      <td>3.68</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 31 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c24b1d9-30e4-4a87-9f0f-9c22e6e71daf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3c24b1d9-30e4-4a87-9f0f-9c22e6e71daf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3c24b1d9-30e4-4a87-9f0f-9c22e6e71daf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5ad23725-1e1d-40e4-879f-c1c02ca7c45d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ad23725-1e1d-40e4-879f-c1c02ca7c45d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5ad23725-1e1d-40e4-879f-c1c02ca7c45d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["\n","\n","---\n","# Transformer Model\n","\n"],"metadata":{"id":"waNhrbSAsk_6"}},{"cell_type":"markdown","source":["**No HP Tuning**: First we will implement our model without HP tuning and try to overfit, to just prove that we have the generalization power, and just check that we can actually set up and run the architecture"],"metadata":{"id":"WSxQ_mLEsXTr"}},{"cell_type":"code","source":["\n","# **Set device for GPU acceleration**\n","# If CUDA (NVIDIA GPU) is available, computations will use it. Otherwise, it defaults to CPU.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","#get data\n","data = df\n","\n","# Separate features (input data) and labels (output/target)\n","X = data.iloc[:, :-1].values\n","y = data.iloc[:, -1].values\n","\n","# **Normalize features**\n","# Standardize the `V1` to `V28` columns (zero mean, unit variance) for numerical stability.\n","# Log-transform the `Amount` column to reduce the effect of large values.\n","scaler = StandardScaler()\n","X[:, :-1] = scaler.fit_transform(X[:, :-1])  # Standardize PCA-transformed features\n","X[:, -1] = np.log1p(X[:, -1])  # Apply log(1 + x) to the 'Amount' column to normalize it\n","\n","# **Split the data into training, validation, and test sets**\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","# **Convert data to PyTorch tensors**\n","train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32).to(device),\n","                           torch.tensor(y_train, dtype=torch.float32).to(device))\n","val_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32).to(device),\n","                         torch.tensor(y_val, dtype=torch.float32).to(device))\n","test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32).to(device),\n","                          torch.tensor(y_test, dtype=torch.float32).to(device))\n","\n","# **DataLoader for batching**\n","batch_size = 64\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=batch_size)\n","test_loader = DataLoader(test_data, batch_size=batch_size)\n","\n","# **2. Custom Positional Embedding Layer (from the book)**\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, sequence_length, input_dim, output_dim):\n","        super(PositionalEmbedding, self).__init__()\n","        # Token embedding: maps each input feature into a higher-dimensional space\n","        self.token_embeddings = nn.Embedding(input_dim, output_dim)\n","        # Position embedding: maps each position in the sequence to a higher-dimensional space\n","        self.position_embeddings = nn.Embedding(sequence_length, output_dim)\n","        self.sequence_length = sequence_length\n","\n","    def forward(self, x):\n","        # Generate positions (0, 1, ..., sequence_length - 1)\n","        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n","        # Lookup embeddings for tokens and positions, then add them\n","        embedded_tokens = self.token_embeddings(x)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","# **3. Define the Transformer Model with Custom Positional Embedding**\n","\n","class FraudDetectionTransformer(nn.Module):\n","    def __init__(self, input_dim, embed_dim, num_heads, ff_dim, num_layers, sequence_length):\n","        super(FraudDetectionTransformer, self).__init__()\n","        # Positional Embedding Layer (from the book)\n","        self.positional_embedding = PositionalEmbedding(sequence_length, input_dim, embed_dim)\n","\n","        # Transformer Encoder Layer (using pre-built PyTorch functionality)\n","        self.encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=embed_dim,  # Dimension of the embedding space\n","            nhead=num_heads,  # Number of attention heads\n","            dim_feedforward=ff_dim,  # Dimension of the feed-forward layer\n","            dropout=0.1  # Dropout for regularization\n","        )\n","        # Stack multiple encoder layers\n","        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n","\n","        # Global Pooling Layer\n","        self.pooling = nn.AdaptiveAvgPool1d(1)\n","\n","        # Fully Connected Output Layer\n","        self.fc = nn.Linear(embed_dim, 1)\n","\n","        # Sigmoid Activation\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        # Get positional embeddings and add them to the token embeddings\n","        x = self.positional_embedding(x)\n","\n","        # Transpose the input to match the shape expected by the transformer (sequence, batch, feature)\n","        x = x.permute(1, 0, 2)  # (batch, seq_len, feature) -> (seq_len, batch, feature)\n","\n","        # Pass through the transformer encoder\n","        x = self.transformer_encoder(x)\n","\n","        # Apply global pooling (average over the sequence length)\n","        x = self.pooling(x.permute(1, 2, 0))  # (seq_len, batch, feature) -> (batch, feature, 1)\n","\n","        # Flatten the output to match the input of the fully connected layer\n","        x = x.view(x.size(0), -1)\n","\n","        # Final classification layer\n","        x = self.fc(x)\n","\n","        # Sigmoid for binary classification (fraud or not)\n","        x = self.sigmoid(x)\n","\n","        return x\n","\n","# **4. Instantiate the Model**\n","input_dim = X_train.shape[1]  # Number of input features\n","embed_dim = 256  # Dimensionality of embedding space\n","num_heads = 4  # Number of attention heads\n","ff_dim = 512  # Feed-forward layer dimension\n","num_layers = 4  # Number of transformer layers\n","sequence_length = X_train.shape[1]  # Sequence length is the number of input features\n","\n","model = FraudDetectionTransformer(input_dim, embed_dim, num_heads, ff_dim, num_layers, sequence_length).to(device)\n","\n","# **5. Training Setup**\n","criterion = nn.BCELoss()  # Binary Cross Entropy loss for binary classification\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# **6. Training Loop**\n","def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n","    model.train()  # Set model to training mode\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()  # Zero the gradients\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","\n","            # Calculate the loss\n","            loss = criterion(outputs.squeeze(), labels)\n","\n","            # Backward pass and optimization\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        # Print training loss for every epoch\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n","\n","        # Optionally, validate the model performance after each epoch (on the validation set)\n","        validate_model(model, val_loader, criterion)\n","\n","# **7. Validation Function**\n","def validate_model(model, val_loader, criterion):\n","    model.eval()  # Set model to evaluation mode\n","\n","    with torch.no_grad():\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","\n","            # Calculate the loss\n","            loss = criterion(outputs.squeeze(), labels)\n","            total_loss += loss.item()\n","\n","            # Calculate accuracy\n","            predicted = (outputs.squeeze() > 0.5).float()\n","            correct += (predicted == labels).sum().item()\n","            total += labels.size(0)\n","\n","        print(f\"Validation Loss: {total_loss/len(val_loader)}, Accuracy: {correct/total * 100}%\")\n","\n","# **8. Start Training**\n","train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)\n","\n","# **9. Testing the Model**\n","def test_model(model, test_loader):\n","    model.eval()  # Set model to evaluation mode\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","\n","            # Calculate accuracy\n","            predicted = (outputs.squeeze() > 0.5).float()\n","            correct += (predicted == labels).sum().item()\n","            total += labels.size(0)\n","\n","        print(f\"Test Accuracy: {correct/total * 100}%\")\n","\n","# **10. Evaluate on the Test Set**\n","test_model(model, test_loader)\n"],"metadata":{"id":"9evuMo2oImJG"},"execution_count":null,"outputs":[]}]}