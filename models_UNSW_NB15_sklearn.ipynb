{"cells":[{"cell_type":"markdown","metadata":{"id":"iuEjIjTkbdSK"},"source":[]},{"cell_type":"markdown","metadata":{"id":"Yhq0AM-GxTw6"},"source":["# Practice run of analysing/testing different models on the UNSW_NB15 dataset, before trying Deep Learning.\n","\n","Prior research suggests this is a largely non-linear, less separable dataset so deep learning may be necessary, but I will try simpler, more interpretable models first for the sake of completeness, and to gain Variable Importances"]},{"cell_type":"markdown","metadata":{"id":"BwpZ83SO1wod"},"source":["Let's load our packages and data"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":720,"status":"ok","timestamp":1730395348872,"user":{"displayName":"Archie Goodman","userId":"05960694724077487952"},"user_tz":0},"id":"WSMa2bmU5XCI","outputId":"a1d8681b-be0d-4487-e0a3-60d629f6810b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Google Drive is already mounted.\n","New run: Packages loaded\n"]}],"source":["#import packages:\n","\n","import os\n","os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n","os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n","\n","from google.colab import drive\n","\n","try:\n","  import google.colab\n","  IN_COLAB = True\n","except:\n","  IN_COLAB = False\n","\n","if IN_COLAB:\n","  # Check if drive is mounted by looking for the mount point in the file system.\n","  # This is a more robust approach than relying on potentially internal variables.\n","  import os\n","  if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","  else:\n","    print(\"Google Drive is already mounted.\")\n","else:\n","  print(\"Not running in Google Colab. Drive mounting skipped.\")\n","\n","\n","import os\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","from tqdm import tqdm\n","\n","\n","print(\"New run: Packages loaded\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5979,"status":"ok","timestamp":1730392255184,"user":{"displayName":"Archie Goodman","userId":"05960694724077487952"},"user_tz":0},"id":"OsQcbrhZyWcN","outputId":"b99930d7-b4b0-4666-fa48-5790ae048983"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data loaded\n"]}],"source":["#if using colabs - will need to first mount your drive\n","\n","#change these for different users\n","\n","# File paths (update if needed)\n","test_set_filepath = '/content/drive/MyDrive/Colab_Notebooks/Data/UNSW_NB15_testing-set.parquet'\n","training_set_filepath = '/content/drive/MyDrive/Colab_Notebooks/Data/UNSW_NB15_training-set.parquet'\n","\n","# Load data\n","test_set = pd.read_parquet(test_set_filepath)\n","train_set = pd.read_parquet(training_set_filepath)\n","\n","print(\"Data loaded\")\n"]},{"cell_type":"markdown","metadata":{"id":"N7RupKUW7OgV"},"source":["The next cell does some basic analysis, and one hot encodes some of the features:"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1730392255184,"user":{"displayName":"Archie Goodman","userId":"05960694724077487952"},"user_tz":0},"id":"VengASbQCV3w"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":854,"status":"ok","timestamp":1730393915320,"user":{"displayName":"Archie Goodman","userId":"05960694724077487952"},"user_tz":0},"id":"PMRXGNRqMAaC","outputId":"fd9061f0-3e6a-4abb-dd1c-b4cd089a3095"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data set preprocessed, columns = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'is_sm_ips_ports', 'label', 'proto_grouped_arp', 'proto_grouped_ospf', 'proto_grouped_other', 'proto_grouped_sctp', 'proto_grouped_tcp', 'proto_grouped_udp', 'proto_grouped_unas', 'service_-', 'service_dhcp', 'service_dns', 'service_ftp', 'service_ftp-data', 'service_http', 'service_irc', 'service_pop3', 'service_radius', 'service_smtp', 'service_snmp', 'service_ssh', 'service_ssl', 'state_CON', 'state_ECO', 'state_FIN', 'state_INT', 'state_PAR', 'state_REQ', 'state_RST', 'state_URN', 'state_no']\n","Class Sizes:\n","Genuine count, Label 0: 56000 rows\n","Positive class, Label 1: 119341 rows\n"]}],"source":["\n","# Preprocessing function (modified for pandas)\n","def preprocess_data(data_set):\n","  if 'attack_cat' in data_set.columns.tolist():\n","    data_set = data_set.drop('attack_cat', axis=1)\n","\n","  if 'proto' in data_set.columns.tolist():\n","    category_percentages = data_set['proto'].value_counts(normalize=True) * 100\n","\n","    top_6_categories = category_percentages.head(6).index.tolist()\n","\n","    data_set['proto_grouped'] = data_set['proto'].apply(lambda x: x if x in top_6_categories else 'other')\n","\n","    data_set = pd.get_dummies(data_set, columns=['proto_grouped'], prefix='proto_grouped')\n","\n","    data_set = data_set.drop('proto', axis=1)\n","\n","  if 'proto_grouped' in data_set.columns.tolist():\n","      data_set = data_set.drop(['proto_grouped'], axis=1)\n","\n","  categorical_cols = data_set.select_dtypes(include=['category']).columns.tolist()\n","  data_set = pd.get_dummies(data_set, columns=categorical_cols, prefix_sep='_')\n","\n","  binary_cols = data_set.select_dtypes(include=['bool']).columns\n","  data_set[binary_cols] = data_set[binary_cols].astype(int)\n","\n","  print(f\"Data set preprocessed, columns = {data_set.columns.tolist()}\")\n","  return data_set\n","\n","train_set = preprocess_data(train_set)\n","\n","class_counts = train_set['label'].value_counts()\n","\n","print(\"Class Sizes:\")\n","print(f\"Genuine count, Label 0: {class_counts[0]} rows\")\n","print(f\"Positive class, Label 1: {class_counts[1]} rows\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eFYJj2gn1rqe"},"source":["NOTE TO SELF -\n","1. THIS IS FOR BINARY CLASSIFICATION, WE WANT MULTICLASS EVENTUALLY, BUT FOR NOW WE WILL JUST DO BN\n"]},{"cell_type":"markdown","metadata":{"id":"sYPGA0w_tgSK"},"source":["Based on the high number of columns in the Proto column, we may want to consider an Embeddings layer with the Deep Learning that we plan to undertake later. However since DT/RF perform somewhat poorly on sparse vector datasets (like one hot encoded ones) we will group all the extremely rare categories into an 'other'.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ZqRkXuXnMjmJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running nested cross-validation for Logistic Regression with oversampling.\n"]},{"name":"stderr","output_type":"stream","text":["3it [00:47, 15.97s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Validation ROC AUC from nested cross-validation (LR): 0.9641\n","Running nested cross-validation for Decision Tree with oversampling.\n"]},{"name":"stderr","output_type":"stream","text":["3it [01:50, 36.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Validation ROC AUC from nested cross-validation (DT): 0.9847\n","Running nested cross-validation for Random Forest with oversampling.\n"]},{"name":"stderr","output_type":"stream","text":["3it [29:04, 581.47s/it]"]},{"name":"stdout","output_type":"stream","text":["Average Validation ROC AUC from nested cross-validation (RF): 0.9892\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\n","\n","def run_models(model_type, X, y):\n","    \"\"\"\n","    Runs Logistic Regression (LR), Decision Tree (DT), or Random Forest (RF) model using nested cross-validation with oversampling.\n","    \"\"\"\n","    # Scale data only for Logistic Regression\n","    if model_type.upper() == 'LR':\n","        scaler = StandardScaler()\n","        X = scaler.fit_transform(X)\n","    else:\n","        X = X.values  # Convert to NumPy array for consistency\n","\n","    # Define outer and inner cross-validation\n","    outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n","    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n","\n","    # Initialize the model and hyperparameter grid\n","    if model_type.upper() == 'LR':\n","        model = LogisticRegression(max_iter=1000)\n","        param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n","        print(\"Running nested cross-validation for Logistic Regression with oversampling.\")\n","    elif model_type.upper() == 'DT':\n","        model = DecisionTreeClassifier()\n","        param_grid = {\n","            'max_depth': [3, 5, 10],\n","            'min_samples_split': [2, 10, 20],\n","            'min_samples_leaf': [1, 5, 10],\n","            'criterion': ['gini', 'entropy']\n","        }\n","        print(\"Running nested cross-validation for Decision Tree with oversampling.\")\n","    elif model_type.upper() == 'RF':\n","        model = RandomForestClassifier()\n","        param_grid = {\n","            'n_estimators': [50, 100, 200],\n","            'max_depth': [3, 5, 10],\n","            'min_samples_split': [2, 10, 20],\n","            'min_samples_leaf': [1, 5, 10],\n","        }\n","        print(\"Running nested cross-validation for Random Forest with oversampling.\")\n","    else:\n","        print(\"Invalid model type. Please choose 'LR', 'DT', or 'RF'.\")\n","        return\n","\n","    # Store outer fold scores\n","    outer_scores = []\n","\n","    # Loop through outer folds\n","    for train_index, val_index in tqdm(outer_cv.split(X, y)):\n","        # Split data into training and validation sets\n","        X_train_fold, X_val_fold = X[train_index], X[val_index]\n","        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n","\n","        # Oversample the training data to account for slight class imbalance\n","        ros = RandomOverSampler(random_state=42)\n","        X_train_resampled, y_train_resampled = ros.fit_resample(X_train_fold, y_train_fold)\n","\n","        # Inner cross-validation with oversampling\n","        grid_search = GridSearchCV(\n","            estimator=model,\n","            param_grid=param_grid,\n","            cv=inner_cv,\n","            scoring='roc_auc',\n","            n_jobs=-1\n","        )\n","\n","        # Fit the model on the resampled training data\n","        grid_search.fit(X_train_resampled, y_train_resampled)\n","\n","        # Evaluate the best model on the validation data\n","        best_model = grid_search.best_estimator_\n","        y_val_pred_proba = best_model.predict_proba(X_val_fold)[:, 1]\n","        best_score = roc_auc_score(y_val_fold, y_val_pred_proba)\n","\n","        # Store the best score\n","        outer_scores.append(best_score)\n","\n","    # Print the average ROC AUC score\n","    print(f\"Average Validation ROC AUC from nested cross-validation ({model_type.upper()}): {np.mean(outer_scores):.4f}\")\n","\n","X = train_set.drop('label', axis=1)\n","y = train_set['label']\n","\n","# Example usage:\n","run_models('LR', X, y)\n","run_models('DT', X, y)\n","run_models('RF', X, y)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNKnjMkMRmyd5loftwncgUy","gpuType":"T4","machine_shape":"hm","mount_file_id":"1bRPN2-9luXnYH0cyOl3DFjyOdCkXkGGk","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}